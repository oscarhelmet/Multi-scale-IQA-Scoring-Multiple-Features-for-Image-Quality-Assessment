{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d734cee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c47bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Dataset/Training_Set/data.csv\", header=None)\n",
    "dataset = StandardScaler().fit_transform(dataset)\n",
    "labels = pd.read_csv(\"Dataset/Training_Set/label.csv\", header=None)\n",
    "labels = labels.astype(int)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dataset = torch.tensor(dataset, device=device)\n",
    "labels = torch.tensor(labels.values, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cca70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(A, self).__init__()\n",
    "        self.layer1 = nn.Linear(64, 64)\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "        \n",
    "        init.kaiming_normal_(self.layer1.weight)\n",
    "        init.kaiming_normal_(self.layer2.weight)\n",
    "        init.kaiming_normal_(self.layer3.weight)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = torch.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2735368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(B, self).__init__()\n",
    "        self.layer1 = nn.Linear(1472, 2944)\n",
    "        self.layer2 = nn.Linear(2944, 5888)\n",
    "        self.layer3 = nn.Linear(5888, 5888)\n",
    "        self.layer4 = nn.Linear(5888, 2994)\n",
    "        self.layer5 = nn.Linear(2994, 1472)\n",
    "        self.layer6 = nn.Linear(1472, 1)\n",
    "        \n",
    "        init.kaiming_normal_(self.layer1.weight)\n",
    "        init.kaiming_normal_(self.layer2.weight)\n",
    "        init.kaiming_normal_(self.layer3.weight)\n",
    "        init.kaiming_normal_(self.layer4.weight)\n",
    "        init.kaiming_normal_(self.layer5.weight)\n",
    "        init.kaiming_normal_(self.layer6.weight)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.relu(self.layer5(x))\n",
    "        x = torch.sigmoid(self.layer6(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b49543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C, self).__init__()\n",
    "        self.layer1 = nn.Linear(64, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, 256)\n",
    "        self.layer4 = nn.Linear(256, 512)\n",
    "        self.layer5 = nn.Linear(512, 256)\n",
    "        self.layer6 = nn.Linear(256, 128)\n",
    "        self.layer7 = nn.Linear(128, 64)\n",
    "        self.layer8 = nn.Linear(64, 1)\n",
    "        \n",
    "        init.kaiming_normal_(self.layer1.weight)\n",
    "        init.kaiming_normal_(self.layer2.weight)\n",
    "        init.kaiming_normal_(self.layer3.weight)\n",
    "        init.kaiming_normal_(self.layer4.weight)\n",
    "        init.kaiming_normal_(self.layer5.weight)\n",
    "        init.kaiming_normal_(self.layer6.weight)\n",
    "        init.kaiming_normal_(self.layer7.weight)\n",
    "        init.kaiming_normal_(self.layer8.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.relu(self.layer5(x))\n",
    "        x = F.relu(self.layer6(x))\n",
    "        x = F.relu(self.layer7(x))\n",
    "        x = torch.sigmoid(self.layer8(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b6fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(num_epochs, model, loss_fn, optimizer, train_dataloader, val_loader):\n",
    "    train_losses = []  # Stores training losses for each epoch\n",
    "    val_losses = []  # Stores validation losses for each epoch\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Ensure the model is in training mode\n",
    "        epoch_training_loss = 0  # For accumulating the loss for this epoch\n",
    "\n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "            preds = model(inputs)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            epoch_training_loss += loss.item()  # Add the loss for this batch\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # Record the average training loss for this epoch\n",
    "        train_losses.append(epoch_training_loss / len(train_dataloader))\n",
    "\n",
    "        model.eval()  # Switch the model to evaluation mode\n",
    "        epoch_val_loss = 0  # For accumulating the loss for this epoch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_input, val_targets in val_loader:\n",
    "                val_input, val_targets = val_input.float().to(device), val_targets.float().to(device)\n",
    "                out = model(val_input)\n",
    "                val_loss = loss_fn(out, val_targets)\n",
    "                epoch_val_loss += val_loss.item()  # Add the loss for this batch\n",
    "\n",
    "        # Record the average validation loss for this epoch\n",
    "        val_losses.append(epoch_val_loss / len(val_loader))\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(\"Epoch [{}/{}], Training loss: {:.4f}, Validation Loss: {:.4f}\"\n",
    "                  .format(epoch + 1, num_epochs, train_losses[-1], val_losses[-1]))\n",
    "\n",
    "    return train_losses, val_losses  # Return the losses for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932577cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([711, 1472])\n",
      "torch.Size([711, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x2994 and 1472x736)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(val_data, batch_size)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# # Train the model.\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m train_losses,val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(num_epochs, model, loss_fn, optimizer, train_dataloader, val_loader)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m     10\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 11\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, targets)\n\u001b[0;32m     13\u001b[0m     epoch_training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Add the loss for this batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m, in \u001b[0;36mB.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x))\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x))\n\u001b[1;32m---> 24\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer6(x))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x2994 and 1472x736)"
     ]
    }
   ],
   "source": [
    "#Input hyperparameter \n",
    "option = 'B'\n",
    "num_epochs = 750\n",
    "batch_size = 128\n",
    "learning_rate= 0.0001\n",
    "\n",
    "if option == 'A':\n",
    "    model = A()\n",
    "    \n",
    "elif option == 'B':\n",
    "    model = B()    \n",
    "else: \n",
    "    model = C()\n",
    "\n",
    "model.to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate)\n",
    "print(dataset.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "# # Making sure shapes are correct and defining dataloader.\n",
    "# input_np_array = np.array(dataset[:,1:-1].tolist(), dtype='float32')\n",
    "# inputs = torch.from_numpy(input_np_array)\n",
    "# # inputs = torch.from_numpy(np.array(dataset.iloc[:,1:-1].values, dtype='float32'))\n",
    "# print(inputs.shape)\n",
    "\n",
    "\n",
    "\n",
    "train_tensor_dataset = TensorDataset(dataset, labels)\n",
    "val_size, train_size = int(0.1 * len(train_tensor_dataset)),  len(train_tensor_dataset) - int(0.1 * len(train_tensor_dataset))\n",
    "train_data, val_data = random_split(train_tensor_dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size)\n",
    "\n",
    "\n",
    "# # Train the model.\n",
    "train_losses,val_losses = fit(num_epochs, model, loss_fn, optimizer, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def evaluate_model(model, val_dataloader, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # Do not calculate gradients since we are only evaluating\n",
    "        for inputs, targets in val_dataloader:\n",
    "            inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += loss_fn(outputs, targets).item()\n",
    "            \n",
    "            # For binary classification, we consider the predicted class to be the one with probability > 0.5\n",
    "            pred = outputs >= 0.5\n",
    "            correct += (pred == targets).sum().item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    accuracy = correct / len(val_dataloader.dataset)\n",
    "\n",
    "    return val_loss, accuracy\n",
    "\n",
    "\n",
    "val_loss, val_accuracy = evaluate_model(model, val_dataloader, loss_fn, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac10445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('Dataset/Test_Set/test.csv' ,header=None)\n",
    "test_labels = pd.read_csv('Dataset/Test_Set/label.csv',header=None)  \n",
    "\n",
    "# 2. Preprocess the test data and labels\n",
    "# test_data = preprocess(test_data)\n",
    "# test_labels = preprocess_labels(test_labels)\n",
    "\n",
    "# 3. Convert DataFrame to DataLoader\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data.values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "test_dataset = TestDataset(test_data, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# 4. Evaluate\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "loss_fn = torch.nn.BCELoss()  # Adjust this to match your loss function\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        print(outputs)\n",
    "\n",
    "        # Reshape the outputs tensor to match the shape of targets\n",
    "        outputs = outputs.view(-1)\n",
    "        \n",
    "        \n",
    "        test_loss += loss_fn(outputs, targets.view(-1)).item()\n",
    "        \n",
    "        # Convert the outputs to boolean values for comparison\n",
    "        pred = outputs >= 0.5\n",
    "        print(\"outputs\")\n",
    "        # Convert targets to boolean values as well\n",
    "        # Option 1\n",
    "        targets = targets.view(-1) >= 0.5\n",
    "        correct += (pred == targets).sum().item()\n",
    "\n",
    "test_loss /= len(test_dataloader)\n",
    "accuracy_test = correct / len(test_dataloader.dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e866bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'model_{option}_{learning_rate}_{batch_size}_{num_epochs}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
